# deepCount
## Deep Built-Structure Counting Using Attention Based Re-weighting

This repository contains code for FusionNet experiment of 'Deep Built-Structure Counting in Satellite Imagery Using Attention Based Re-weighting' published in ISPRS Journal 2019. Following are the main modules/files of the code:

### 1. DenseNet Features:
    We have used DenseNet as backbone of our counting pipeline. The folder 'DenseNet' contains a notebook called DenseNet_Feature_Extractor.ipynb'. We extract 'pool5' layer feature vector and 'Relu5_blk' layer features volume from DenseNet one by one. Users need to uncomment the corresponding line for extracting specific features.
    
    Inputs:
          1. A text file that contains names of image files for which features are to be extracted
          2. Images folder path
          3. Output folder
      
    Output:
          1. Feature Maps (.mat files)
      
### 2. SSNet:
    Satellite Segmentation Network is the model that predicts per pixel probability of built-up presence in an image. This model is used as attention map for DenseNet feature volumes. The folder SSNet contains a notebook called ''.
    
    Inputs:
      1. A text file that contains names of image files for which features are to be extracted
      2. Images folder path
      3. Output folder
      
    Output:
      1. Attention Maps (.mat files)
      
### 3. Product Maps:
    To introduce attention in the feature maps, a MATLAB script called 'pgap_weighted_summation.m' is used to multiply the SSNet Probability Maps and DenseNet 'relu5_blk' maps. A python version of the script is also provided called 'fuse_maps.ipynb' with the only difference that it does not perform 'anti-aliasing' which MATLAB performs by default.
     Inputs:
      1. fmap_path (folder path that contains relu5_blk feature maps)
      2. detection_path (folder path that contains SSNet probability maps)
      3. output_path (folder path for output product maps)
      4. output_path1 (folder path for output vectors generated by global average pooling of product maps)
      
    Output:
      1. Product Maps (.mat files)
      2. Global Weighted Average Pooled (GAP) Feature Vectors (.mat files)
      
 ### 4. FusionNet Model:
     The notebook called 'FusionNet.ipynb' contains code for training and testing FusionNet.
     
     Inputs:
      1. Product Maps
      2. GAP vectors
      3. pool5 feature vectors
      4. Text file containing training images filenames
      5. Text file containing testing images filenames
      6. Folder path to save model weights
      
     Outputs:
      1. Trained model weights (.hdf5 files)
      
      
 ### 5. Citation:
 @article{shakeel2019deep,
  title={Deep built-structure counting in satellite imagery using attention based re-weighting},
  author={Shakeel, Anza and Sultani, Waqas and Ali, Mohsen},
  journal={ISPRS Journal of Photogrammetry and Remote Sensing},
  volume={151},
  pages={313--321},
  year={2019},
  publisher={Elsevier}
}
 
      
