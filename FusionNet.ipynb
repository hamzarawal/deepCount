{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from keras.optimizers import SGD, Adagrad, Adadelta, RMSprop, Adam, Nadam\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Concatenate, LeakyReLU, UpSampling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import RMSprop, Adam, Adadelta\n",
    "from keras.callbacks import Callback, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------\n",
    "#  Input Maps Folders\n",
    "#---------------------------\n",
    "training_labels_path = 'E:/training_filenames.txt'\n",
    "test_labels_path = 'E:/testing_filenames.txt'\n",
    "pool5_features = 'E:/pool5_feats'\n",
    "gap_features = 'E:/GAP_feats'\n",
    "product_maps = 'E:/product_maps'\n",
    "\n",
    "#------------------\n",
    "#  Outputs\n",
    "#------------------\n",
    "final_results_path = 'E:/results.txt'    \n",
    "weights_savepath = 'E:/FusionNet/weights/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "#  Data Generator function to generate batches according to batch size\n",
    "#---------------------------------------------------------------------\n",
    "def generator(train_indices, batch_size, itr, lines, image_size=336):\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    batch_pmap = []\n",
    "    batch_product = []\n",
    "    startInd = itr*batch_size\n",
    "    endInd = startInd + batch_size\n",
    "    p_mapsize = 32\n",
    "    fmap_size = 42\n",
    "    \n",
    "    for i in range(startInd, endInd):\n",
    "        line = lines[i].split(' ')\n",
    "        \n",
    "        #pool5 features\n",
    "        image_path = os.path.join(pool5_features, line[0] + '.mat')\n",
    "        fmap1 = sio.loadmat(image_path)\n",
    "        fmap1 = fmap1['fmap']\n",
    "        fmap = fmap1.ravel()\n",
    "        \n",
    "        #GAP features\n",
    "        image_path1 = os.path.join(gap_features, line[0] + '.mat')\n",
    "        fmap11 = sio.loadmat(image_path1)\n",
    "        fmap11 = fmap11['Pgap']\n",
    "        fmap1 = fmap11.ravel()\n",
    "        \n",
    "        #product maps\n",
    "        image_path2 = os.path.join(product_maps, line[0] + '.mat')\n",
    "        fmap22 = sio.loadmat(image_path2)\n",
    "        fmap22 = fmap22['product_pmap']\n",
    "        fmap2 = np.zeros((fmap_size,fmap_size,1024))\n",
    "        fmap2[:,:,:] = fmap22[:,:,:]\n",
    "        \n",
    "        batch_images.append(fmap)\n",
    "        batch_pmap.append(fmap1)\n",
    "        batch_product.append(fmap2)\n",
    "        batch_labels.append(np.int(line[1]))\n",
    "        \n",
    "    batch_images = np.array(batch_images, dtype=np.float32)\n",
    "    batch_pmap = np.array(batch_pmap, dtype=np.float32)\n",
    "    batch_product = np.array(batch_product, dtype=np.float32)\n",
    "    batch_labels = np.array(batch_labels, dtype=np.float32)\n",
    "    \n",
    "    \n",
    "    return batch_images, batch_pmap, batch_product, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# RMSE loss function\n",
    "#------------------------\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------\n",
    "#  SSNet Model\n",
    "#--------------\n",
    "def create_model():\n",
    "    \n",
    "    f_map = Input(shape=(1024,), name='DenseNet')\n",
    "    p_map = Input(shape=(1024,), name='SSNEt')\n",
    "    prod_map = Input(shape=(42,42,1024), name='product')\n",
    "    \n",
    "    x_d = Dense(512, init='glorot_normal')(f_map)\n",
    "    x_d = LeakyReLU(alpha=0.3)(x_d)\n",
    "    x_d = Dropout(0.5)(x_d)\n",
    "    \n",
    "    x_s = Dense(512, init='glorot_normal')(p_map)\n",
    "    x_s = LeakyReLU(alpha=0.3)(x_s)\n",
    "    x_s = Dropout(0.5)(x_s)\n",
    "    \n",
    "    x_p = Convolution2D(1, (1, 1), init='glorot_normal', W_regularizer=l1(0.001))(prod_map)\n",
    "    x_p = LeakyReLU(alpha=0.3)(x_p)\n",
    "    x_p = Flatten()(x_p)\n",
    "    x_p = Dense(512, init='glorot_normal')(x_p)\n",
    "    x_p = LeakyReLU(alpha=0.3)(x_p)\n",
    "    x_p = Dropout(0.5)(x_p)\n",
    "    \n",
    "    \n",
    "    x = Concatenate(axis=-1)([x_d,  x_s, x_p]) \n",
    "    x = Dense(512, init='glorot_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(32, init='glorot_normal')(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1, init='glorot_normal')(x)    \n",
    "    x = Activation('linear')(x)\n",
    "    \n",
    "    adagrad=Adagrad(lr=0.01, epsilon=1e-08)\n",
    "    \n",
    "    model_finetune = Model(inputs=[f_map, p_map, prod_map], outputs=x)    \n",
    "    model_finetune.compile(loss=root_mean_squared_error, optimizer=adagrad, metrics=['accuracy'])\n",
    "    return model_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#   Model Training\n",
    "#------------------------------\n",
    "\n",
    "\n",
    "#Model Parameters\n",
    "batch_size = 1\n",
    "nb_epoch = 3000\n",
    "\n",
    "model = create_model()\n",
    "lines = [line.rstrip('\\n') for line in open(training_labels_path)]\n",
    "\n",
    "indices = np.arange(len(lines))\n",
    "train_indices = indices[:]\n",
    "print(train_indices.shape)\n",
    "iterations_t = np.int(len(train_indices)/batch_size)\n",
    "t_loss_ep = []\n",
    "\n",
    "#loop for number of epochs\n",
    "for epoch in range(nb_epoch):\n",
    "    \n",
    "    t_loss = []\n",
    "    start = time.time()\n",
    "    \n",
    "    for i in range(iterations_t):\n",
    "        X_train, X_pmap, X_prod, y_train = generator(train_indices, batch_size, i, lines, image_size=336)  \n",
    "        history = model.fit([X_train, X_pmap, X_prod], y_train, verbose=0)\n",
    "        t_loss.append(history.history['loss'])\n",
    "     \n",
    "    stop = time.time()\n",
    "    duration = stop - start\n",
    "    t_loss_ep.append(np.mean(np.array(t_loss, dtype=np.float32)))\n",
    "    print(\"Epoch: {}  Training Loss: {}  Time: {} sec\".format(epoch+209, t_loss_ep[epoch], duration) )\n",
    "    \n",
    "    #save weigths for each epoch      \n",
    "    model_name = weights_savepath + str(epoch) + \"_Epochs.hdf5\"\n",
    "    model.save_weights(model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#   Model Testing\n",
    "#------------------------------\n",
    "\n",
    "lines = [line.rstrip('\\n') for line in open(test_labels_path)]\n",
    "\n",
    "#Load weigth. Please replace XXX with the epoch number upto which the model was trained\n",
    "model.load_weights(weights_savepath + str(XXX) + '_Epochs.hdf5')\n",
    "\n",
    "data = \"\"\n",
    "data_low = \"\"\n",
    "data_low_gt = \"\"\n",
    "data_high = \"\"\n",
    "data_high_gt = \"\"\n",
    "data_medium = \"\"\n",
    "data_medium_gt = \"\"\n",
    "\n",
    "mean_abs_error = 0\n",
    "mean_sqrd_error = 0\n",
    "\n",
    "mean_abs_error_low = 0\n",
    "mean_sqrd_error_low = 0\n",
    "\n",
    "mean_abs_error_high = 0\n",
    "mean_sqrd_error_high = 0\n",
    "\n",
    "mean_abs_error_medium = 0\n",
    "mean_sqrd_error_medium = 0\n",
    "\n",
    "total_data = len(lines)\n",
    "count = 0\n",
    "count_low = 0\n",
    "count_high = 0\n",
    "count_medium = 0\n",
    "fmap_size = 42\n",
    "p_mapsize = 32\n",
    "\n",
    "print(len(lines))\n",
    "for i in range(len(lines)):\n",
    "    line = lines[i].split(' ')\n",
    "\n",
    "    image_path = os.path.join('E:/ITU/Dr_Mohsen/houseCounting/new_data_fmaps/pool5', line[0] + '.mat')\n",
    "    fmap1 = sio.loadmat(image_path)\n",
    "    fmap1 = fmap1['fmap']\n",
    "    fmap = fmap1.ravel()\n",
    "    test_image = np.zeros((1,1024))\n",
    "    test_image[0,:] = fmap\n",
    "\n",
    "    image_path1 = os.path.join('E:/ITU/Dr_Mohsen/houseCounting/new_data_fmaps/pgap_maps', line[0] + '.mat')\n",
    "    fmap11 = sio.loadmat(image_path1)\n",
    "    fmap11 = fmap11['Pgap']\n",
    "    fmap1 = fmap11.ravel()\n",
    "    test_pmap = np.zeros((1,1024))\n",
    "    test_pmap[0, :] = fmap1\n",
    "    \n",
    "    image_path2 = os.path.join('E:/ITU/Dr_Mohsen/houseCounting/new_data_fmaps/pf_maps', line[0] + '.mat')\n",
    "    fmap22 = sio.loadmat(image_path2)\n",
    "    fmap22 = fmap22['pfmap']\n",
    "    fmap2 = np.zeros((fmap_size,fmap_size,1024))\n",
    "    fmap2[:,:,:] = fmap22[:,:,:]\n",
    "    test_product = np.zeros((1,42,42,1024))\n",
    "    test_product[0, :, :, :] = fmap2\n",
    "         \n",
    "    \n",
    "    output = model.predict([test_image, test_pmap, test_product])\n",
    "    if output < 0:\n",
    "        output = 0\n",
    "        \n",
    "#     print(line[0], ' ', output)\n",
    "    print([gt_count, output])\n",
    "    \n",
    "    \n",
    "    #calculating in various count ranges as described in paper\n",
    "    abs_error = np.abs(gt_count - output)\n",
    "    mean_abs_error = mean_abs_error + abs_error\n",
    "    \n",
    "    sqrd_error = (gt_count - output) * (gt_count - output)\n",
    "    mean_sqrd_error = mean_sqrd_error + sqrd_error  \n",
    "    \n",
    "    if gt_count >= 0 and gt_count <= 30:\n",
    "            count_low = count_low + 1\n",
    "            mean_abs_error_low = mean_abs_error_low + abs_error\n",
    "            mean_sqrd_error_low = mean_sqrd_error_low + sqrd_error\n",
    "            data_low = data_low + line[0] + \" \" + str(float(output)) + \"\\n\"\n",
    "            data_low_gt = data_low_gt + line[0] + \" \" + str(float(gt_count)) + \"\\n\"\n",
    "        \n",
    "    if gt_count >= 61 and gt_count <= 100:\n",
    "            count_high = count_high + 1\n",
    "            mean_abs_error_high = mean_abs_error_high + abs_error\n",
    "            mean_sqrd_error_high = mean_sqrd_error_high + sqrd_error\n",
    "            data_high = data_high + line[0] + \" \" + str(float(output)) + \"\\n\"\n",
    "            data_high_gt = data_high_gt + line[0] + \" \" + str(float(gt_count)) + \"\\n\"\n",
    "            \n",
    "    if gt_count >= 31 and gt_count <= 60:\n",
    "            count_medium = count_medium + 1\n",
    "            mean_abs_error_medium = mean_abs_error_medium + abs_error\n",
    "            mean_sqrd_error_medium = mean_sqrd_error_medium + sqrd_error\n",
    "            data_medium = data_medium + line[0] + \" \" + str(float(output)) + \"\\n\"\n",
    "            data_medium_gt = data_medium_gt + line[0] + \" \" + str(float(gt_count)) + \"\\n\"\n",
    "    \n",
    "    \n",
    "    data = data + line[0] + \" \" + str(float(output)) + \"\\n\"\n",
    "\n",
    "#write final results into a text file\n",
    "f = open(final_results_path,'w')\n",
    "f.write(data)\n",
    "\n",
    "f_mean_abs_error = mean_abs_error / total_data\n",
    "f_mean_sqrd_error = mean_sqrd_error / total_data\n",
    "\n",
    "f_mean_abs_error_low = mean_abs_error_low / count_low\n",
    "f_mean_sqrd_error_low = mean_sqrd_error_low / count_low\n",
    "\n",
    "f_mean_abs_error_high = mean_abs_error_high / count_high\n",
    "f_mean_sqrd_error_high = mean_sqrd_error_high / count_high\n",
    "\n",
    "f_mean_abs_error_medium = mean_abs_error_medium / count_medium\n",
    "f_mean_sqrd_error_medium = mean_sqrd_error_medium / count_medium\n",
    "\n",
    "print('##################################### ERROR VALUES ###########################################')\n",
    "print(\"Mean Squared Error: {} \".format(f_mean_sqrd_error))\n",
    "print(\"Mean Absolute Error: {} \".format(f_mean_abs_error))\n",
    "print(\"Number of Instances: {} \".format(total_data))\n",
    "print('##############################################################################################')\n",
    "\n",
    "print('##################################### ERROR VALUES-LOW ###########################################')\n",
    "print(\"Mean Squared Error: {} \".format(f_mean_sqrd_error_low))\n",
    "print(\"Mean Absolute Error: {} \".format(f_mean_abs_error_low))\n",
    "print(\"Number of Instances: {} \".format(count_low))\n",
    "print('##############################################################################################')\n",
    "\n",
    "print('##################################### ERROR VALUES-MEDIUM ###########################################')\n",
    "print(\"Mean Squared Error: {} \".format(f_mean_sqrd_error_medium))\n",
    "print(\"Mean Absolute Error: {} \".format(f_mean_abs_error_medium))\n",
    "print(\"Number of Instances: {} \".format(count_medium))\n",
    "print('##############################################################################################')\n",
    "\n",
    "print('##################################### ERROR VALUES-HIGH ###########################################')\n",
    "print(\"Mean Squared Error: {} \".format(f_mean_sqrd_error_high))\n",
    "print(\"Mean Absolute Error: {} \".format(f_mean_abs_error_high))\n",
    "print(\"Number of Instances: {} \".format(count_high))\n",
    "print('##############################################################################################')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
